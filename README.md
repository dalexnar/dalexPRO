# DALEX v0.5.0

Agente de Inteligencia Artificial con soporte para modo lite y pro.

## Modos de OperaciÃ³n

| CaracterÃ­stica | Lite (Fase 3) | Pro (Fase 4) |
|---------------|---------------|--------------|
| PlanificaciÃ³n | âœ… | âœ… |
| EjecuciÃ³n de skills | âœ… | âœ… |
| AutocorrecciÃ³n | âœ… | âœ… |
| Memoria episÃ³dica | âŒ | âœ… |
| Memoria semÃ¡ntica | âŒ | âœ… ChromaDB |
| Memoria de errores | âŒ | âœ… |

## Requisitos

- Python 3.11+
- Ollama con modelo `qwen2.5:7b`

```bash
# Verificar Ollama
ollama list
# Si no tienes el modelo:
ollama pull qwen2.5:7b
```

## InstalaciÃ³n

### OpciÃ³n 1: Docker (Recomendado)

```bash
# Copiar configuraciÃ³n
cp .env.example .env

# Editar .env segÃºn necesites
# DALEX_MODE=lite  o  DALEX_MODE=pro

# Construir y ejecutar
docker-compose up -d

# Ver logs
docker-compose logs -f
```

### OpciÃ³n 2: Manual

```bash
# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# o: venv\Scripts\activate  # Windows

# Instalar dependencias
pip install -r requirements.txt

# Si usas modo pro, instalar ChromaDB:
pip install chromadb

# Configurar
export DALEX_MODE=lite
export OLLAMA_HOST=http://localhost:11434

# Ejecutar
python main.py
```

## ConfiguraciÃ³n

### Variables de Entorno (prioridad sobre YAML)

| Variable | Default | DescripciÃ³n |
|----------|---------|-------------|
| `DALEX_MODE` | `lite` | `lite` o `pro` |
| `OLLAMA_HOST` | `http://localhost:11434` | URL de Ollama |
| `OLLAMA_MODEL` | `qwen2.5:7b` | Modelo a usar |
| `API_PORT` | `8000` | Puerto de la API |
| `DATABASE_URL` | SQLite local | URL de base de datos |

### Archivo YAML (config/dalex.yaml)

El archivo YAML sirve como configuraciÃ³n base. Las variables de entorno tienen prioridad.

## API

### Endpoints Principales

```bash
# Enviar mensaje
curl -X POST http://localhost:8000/mensajes \
  -H "Content-Type: application/json" \
  -d '{"mensaje": "Hola, Â¿quÃ© puedes hacer?"}'

# Estado del agente
curl http://localhost:8000/estado

# Skills disponibles
curl http://localhost:8000/skills
```

### DocumentaciÃ³n

- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

## Arquitectura

```
dalex/
â”œâ”€â”€ config/           # ConfiguraciÃ³n (ENV > YAML)
â”œâ”€â”€ core/             # Motor del agente
â”‚   â”œâ”€â”€ agente.py     # Loop principal
â”‚   â”œâ”€â”€ planificador.py
â”‚   â”œâ”€â”€ ejecutor.py
â”‚   â””â”€â”€ autocorreccion.py
â”œâ”€â”€ memoria/
â”‚   â”œâ”€â”€ base.py       # Modelos SQLAlchemy
â”‚   â”œâ”€â”€ operaciones.py
â”‚   â””â”€â”€ avanzada/     # Solo modo pro
â”œâ”€â”€ skills/           # Capacidades
â”œâ”€â”€ api/              # FastAPI
â””â”€â”€ integraciones/
    â””â”€â”€ llm/          # ConexiÃ³n con Ollama
```

## Uso

### Flujo BÃ¡sico

1. Usuario envÃ­a mensaje
2. Agente genera plan
3. Si es simple â†’ ejecuta automÃ¡ticamente
4. Si es complejo â†’ pide aprobaciÃ³n
5. Usuario aprueba/rechaza
6. Agente ejecuta y responde

### Ejemplo de ConversaciÃ³n

```
Usuario: Â¿QuÃ© es Python?
Agente: Python es un lenguaje de programaciÃ³n...

Usuario: Crea un script que calcule factoriales
Agente: ðŸ“‹ Plan: Crear script de factoriales
        1. ðŸ’¬ Generar cÃ³digo Python para calcular factoriales
        Â¿Apruebas este plan? (sÃ­/no)

Usuario: sÃ­
Agente: [ejecuta el plan y responde con el cÃ³digo]
```

## Desarrollo

### Agregar Nueva Skill

1. Crear carpeta en `skills/`
2. Agregar `SKILL.md` con la definiciÃ³n
3. Reiniciar el agente

### Cambiar de Modo

```bash
# En .env
DALEX_MODE=pro

# O como variable de entorno
export DALEX_MODE=pro
docker-compose up -d
```

## Troubleshooting

### Error: "No se pudo conectar con el LLM"

1. Verificar que Ollama estÃ¡ corriendo: `ollama list`
2. Verificar la URL: `curl http://localhost:11434/api/tags`
3. Si usas Docker, verificar que `host.docker.internal` resuelve

### Error: "Modelo no encontrado"

```bash
ollama pull qwen2.5:7b
```

### Modo Pro sin ChromaDB

Si ChromaDB no estÃ¡ instalado, la memoria semÃ¡ntica se desactiva pero el agente sigue funcionando.

```bash
pip install chromadb
```
